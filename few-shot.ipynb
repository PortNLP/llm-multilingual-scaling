{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2164b5c79c8cbf8",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Make few-shot samples for SIB-200 dataset to select n samples for each category\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "n = 2  # Number of samples to select for each category\n",
    "# Data directory containing multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "# Output directory for saving few-shot samples\n",
    "output_directory = f\"few-shot/sib-200/train-samples/{n}-shot\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "for language in os.listdir(data_directory):\n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"train.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Group the DataFrame by category and select the same index for each category\n",
    "            few_shot_df = df.groupby('category').apply(lambda x: x.iloc[:n]).reset_index(drop=True)\n",
    "\n",
    "            # Save the few-shot samples to a new CSV file in the output directory\n",
    "            few_shot_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            few_shot_df.to_csv(few_shot_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe709ad1c9d26ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T19:43:28.872602170Z",
     "start_time": "2024-02-06T19:42:37.401534677Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Few-Shot learning for SIB-200 dataset by using generation\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import XGLMTokenizer, XGLMForCausalLM\n",
    "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "n = 2  # Number of samples to select for each category\n",
    "\n",
    "# Create a list of 204 shuffled arrays\n",
    "random_array = np.array([np.random.permutation(np.arange(n * 7)) for _ in range(204)])\n",
    "\n",
    "for model_address in [\"bigscience/bloom-560m\", \"bigscience/bloom-1b1\", \"bigscience/bloom-1b7\", \"bigscience/bloom-3b\"]:\n",
    "    # Filter out FutureWarning messages\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    # Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "    data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "    # Output directory for saving DataFrames\n",
    "    output_directory = f\"few-shot/sib-200/{n}-shot/\" + model_address[model_address.find('/')+1:] + \"/generate\"\n",
    "\n",
    "    if model_address.startswith(\"facebook\"):\n",
    "        # Load learning model and tokenizer\n",
    "        model = XGLMForCausalLM.from_pretrained(model_address)\n",
    "        tokenizer = XGLMTokenizer.from_pretrained(model_address)\n",
    "    if model_address.startswith(\"bigscience\"):\n",
    "        # Load learning model and tokenizer\n",
    "        model = BloomForCausalLM.from_pretrained(model_address)\n",
    "        tokenizer = BloomTokenizerFast.from_pretrained(model_address)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    alternatives = [\" science\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "    alt_tokens = tokenizer.encode(\" \".join(alternatives), add_special_tokens=False)[:-1] # Remove the last token because \"geography\" is 2 tokens!\n",
    "\n",
    "    # Function to predict category given text\n",
    "    def predict_category(prompt):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "        result_length = len(tokens) + 10\n",
    "        outputs = model.generate(inputs[\"input_ids\"],\n",
    "                                 max_length=result_length,\n",
    "                                 output_scores=True,\n",
    "                                 return_dict_in_generate=True\n",
    "                                 )\n",
    "        scores = outputs.scores[0][0][alt_tokens]\n",
    "        found_label = alternatives[torch.argmax(scores)]\n",
    "        confidence = F.softmax(scores, dim=0)[torch.argmax(scores)].item()\n",
    "        return found_label, confidence\n",
    "\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Undone set:\n",
    "    undone = set(os.listdir(data_directory)) - set([string[:-4] for string in os.listdir(output_directory)])\n",
    "\n",
    "    # Iterate through subdirectories in the data directory\n",
    "    for language in tqdm(undone, total=len(undone), desc=\"Languages\"):\n",
    "        # Initialize an empty DataFrame to store results\n",
    "        results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category'])\n",
    "\n",
    "        subdir = os.path.join(data_directory, language)\n",
    "        # Read the test.tsv file into a DataFrame\n",
    "        file_path = os.path.join(subdir, \"test.tsv\")\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "        # Read few-shot samples into a DataFrame\n",
    "        few_shot_df = pd.read_csv(os.path.join(f\"few-shot/sib-200/train-samples/{n}-shot\", f'{language}.csv'))\n",
    "        few_shot_df['category'] = few_shot_df['category'].replace('science/technology', 'science')\n",
    "\n",
    "        # Iterate through rows and compare predicted category with actual category\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['text']\n",
    "            actual_category = row['category']\n",
    "\n",
    "            if model_address.startswith(\"facebook\"):\n",
    "                # Predict category for XGLM\n",
    "                with torch.no_grad():  # Disable gradient calculation\n",
    "                    few_shots_prompt = '\\n'.join(few_shot_df.loc[random_array[index]].apply(lambda row: f\"What is the category of the following SENTENCE?\\nSENTENCE: {row['text']}\\nCategory: {row['category']}\", axis=1))\n",
    "                    predicted_category, confidence = predict_category(few_shots_prompt + \"\\nWhat is the category of the following SENTENCE?\\nSENTENCE: \" + text + \"\\nCategory: \")\n",
    "\n",
    "            if model_address.startswith(\"bigscience\"):\n",
    "                # Predict category for BLOOM\n",
    "                with torch.no_grad():  # Disable gradient calculation\n",
    "                    few_shots_prompt = '\\n'.join(few_shot_df.loc[random_array[index]].apply(lambda row: f\"This tool labels the category of the sentence.\\nSENTENCE: {row['text']}\\nLABEL: {row['category']}\", axis=1))\n",
    "                    predicted_category, confidence = predict_category(few_shots_prompt + \"\\nThis tool labels the category of the sentence.\\nOPTIONS:\\n- science\\n- travel\\n- politics\\n- sports\\n- health\\n- entertainment\\n- geography\\nSENTENCE: \" + text + \"\\nLABEL: \")\n",
    "\n",
    "            # Append the results to the DataFrame\n",
    "            results_df = results_df.append({'text': text,\n",
    "                                            'actual_category': actual_category,\n",
    "                                            'predicted_category': 'science/technology' if predicted_category == ' science' else predicted_category,\n",
    "                                            'confidence': confidence\n",
    "                                            }, ignore_index=True)\n",
    "            torch.cuda.empty_cache()\n",
    "        # Save the results DataFrame to a CSV file in the output directory\n",
    "        results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "        results_df.to_csv(results_file_path, index=False)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    # print(f\"F1 score of {language} is {f1_score(results_df['actual_category'], results_df['predicted_category'], average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f91191a5ea918d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T17:49:38.028962985Z",
     "start_time": "2024-02-10T17:49:35.950284287Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"SIB-200 languages - ACL.xlsx\")\n",
    "\n",
    "# Calculte F1 score for each language and add it to the DataFrame\n",
    "def calculate_f1(language, model, method, n):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    try:\n",
    "        results_df = pd.read_csv(f\"few-shot/sib-200/{n}-shot/{model}/{method}/{language}.csv\")\n",
    "    except FileNotFoundError:\n",
    "        return\n",
    "\n",
    "    # Replace NaN values with 'N/A'\n",
    "    results_df = results_df.fillna('N/A')\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1 = f1_score(results_df['actual_category'], results_df['predicted_category'], average='macro')\n",
    "\n",
    "    # Add the F1 score to the DataFrame\n",
    "    df.loc[df['Folder Name'] == language, f'F1 {model} {method} {n}-shot'] = f1\n",
    "\n",
    "# Iterate through languages and calculate F1 score for each language\n",
    "for language in df['Folder Name']:\n",
    "    calculate_f1(language, \"bloomz-3b\", \"generate\", 2)\n",
    "    calculate_f1(language, \"bloomz-7b1\", \"generate\", 2)\n",
    "\n",
    "# Save the updated DataFrame to the Excel file\n",
    "df.to_excel(\"SIB-200 languages - ACL.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570a1c841ca94f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:20:07.357077204Z",
     "start_time": "2024-02-02T23:20:07.023963983Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"SIB-200 languages - ACL.xlsx\")\n",
    "filtered_df = df[df['Folder Name'].isin(['eng_Latn', 'pes_Arab', 'hin_Deva', 'npi_Deva'])]\n",
    "\n",
    "# Create a line plot of the F1 scores\n",
    "plt.figure(figsize=(20, 10))\n",
    "for language in filtered_df['Folder Name']:\n",
    "    plt.plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "             [filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-560M top_logprobs'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-560m top_logprobs 2-shot'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-560m top_logprobs 5-shot'].values[0]],\n",
    "             label=f'{language} - bloom-560m')\n",
    "\n",
    "    plt.plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "             [filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b1 top_logprobs'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b1 top_logprobs 2-shot'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b1 top_logprobs 5-shot'].values[0]],\n",
    "             label=f'{language} - bloom-1b1')\n",
    "\n",
    "    plt.plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "             [filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b7 top_logprobs'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b7 top_logprobs 2-shot'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-1b7 top_logprobs 5-shot'].values[0]],\n",
    "             label=f'{language} - bloom-1b7')\n",
    "\n",
    "    plt.plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "             [filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-3b top_logprobs'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-3b top_logprobs 2-shot'].values[0],\n",
    "              filtered_df.loc[filtered_df['Folder Name']==language, 'F1 bloom-3b top_logprobs 5-shot'].values[0]],\n",
    "             label=f'{language} - bloom-3b')\n",
    "\n",
    "plt.title('F1 scores for each language')\n",
    "plt.xlabel('Shot')\n",
    "plt.ylabel('F1 score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0f8721bdbc1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-02T23:24:28.037806770Z",
     "start_time": "2024-02-02T23:24:27.859650244Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"SIB-200 languages - ACL.xlsx\")\n",
    "filtered_df = df[df['Folder Name'].isin(['eng_Latn', 'pes_Arab', 'hin_Deva', 'npi_Deva'])]\n",
    "\n",
    "# Initialize an empty DataFrame to store reshaped data\n",
    "reshaped_df = pd.DataFrame()\n",
    "\n",
    "# Reshape the DataFrame so that each row corresponds to a model\n",
    "for model in ['bloom-560m', 'bloom-1b1', 'bloom-1b7', 'bloom-3b']:\n",
    "    model_data = filtered_df[filtered_df.columns[pd.Series(filtered_df.columns).str.startswith(f'F1 {model} top_logprobs')]].copy()\n",
    "    model_data.columns = ['Zero-shot', '2-shot', '5-shot']\n",
    "    model_data.loc[:, 'Model'] = model  # Using .loc to assign values\n",
    "    reshaped_df = pd.concat([reshaped_df, model_data], ignore_index=True)\n",
    "\n",
    "# Group by the 'Model' column and calculate the mean F1 scores for each shot\n",
    "grouped_df = reshaped_df.groupby('Model').mean()\n",
    "\n",
    "# Create a line plot of the mean F1 scores for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model in grouped_df.index:\n",
    "    plt.plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "             grouped_df.loc[model].values,\n",
    "             label=f'{model}')\n",
    "\n",
    "plt.title('Mean F1 scores for each model')\n",
    "plt.xlabel('Shot')\n",
    "plt.ylabel('Mean F1 score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0527739d46e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T01:44:19.884746750Z",
     "start_time": "2024-01-31T01:44:19.248930889Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"SIB-200 languages - ACL.xlsx\")\n",
    "languages = ['eng_Latn', 'pes_Arab', 'hin_Deva', 'npi_Deva']\n",
    "\n",
    "# Create subplots for each language\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "for idx, language in enumerate(languages):\n",
    "    # Filter the DataFrame for the current language\n",
    "    filtered_df = df[df['Folder Name'] == language]\n",
    "\n",
    "    # Initialize an empty DataFrame to store reshaped data\n",
    "    reshaped_df = pd.DataFrame()\n",
    "\n",
    "    # Reshape the DataFrame so that each row corresponds to a model\n",
    "    for model in ['bloom-560m', 'bloom-1b1', 'bloom-1b7', 'bloom-3b']:\n",
    "        model_data = filtered_df[filtered_df.columns[pd.Series(filtered_df.columns).str.startswith(f'F1 {model} top_logprobs')]].copy()\n",
    "        model_data.columns = ['Zero-shot', '2-shot', '5-shot']\n",
    "        model_data.loc[:, 'Model'] = model  # Using .loc to assign values\n",
    "        reshaped_df = pd.concat([reshaped_df, model_data], ignore_index=True)\n",
    "\n",
    "    # Group by the 'Model' column and calculate the mean F1 scores for each shot\n",
    "    grouped_df = reshaped_df.groupby('Model').mean()\n",
    "\n",
    "    # Plot the mean F1 scores for each model\n",
    "    for model in grouped_df.index:\n",
    "        axes[idx].plot(['Zero-shot', '2-shot', '5-shot'],\n",
    "                       grouped_df.loc[model].values,\n",
    "                       label=f'{model}')\n",
    "    axes[idx].set_title(f'F1 scores for {language}')\n",
    "    axes[idx].set_xlabel('Shot')\n",
    "    axes[idx].set_ylabel('Mean F1 score')\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Adjust layout to prevent overlap of subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c134bda085f308",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
