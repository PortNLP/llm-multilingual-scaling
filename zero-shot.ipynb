{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bjn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/epo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kas_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mni_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/guj_Gujr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lvs_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kat_Geor.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/asm_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ibo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ewe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/acq_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/run_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/zul_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kea_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/zsm_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fao_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ace_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pbt_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bem_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/apc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/cym_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/vie_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/taq_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fra_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pes_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/zho_Hans.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/npi_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tha_Thai.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/som_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/est_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/min_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tgl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ast_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/gla_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mar_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/cat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/aka_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/knc_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/swe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ory_Orya.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/afr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/srd_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/szl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ssw_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ilo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mag_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ind_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kbp_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ayr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ajp_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/shn_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lao_Laoo.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/luo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lim_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/oci_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/twi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/plt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/arb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tat_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/war_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/snd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/taq_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ron_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hrv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bak_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kac_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/cjk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/azj_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hau_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/wol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sot_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/jpn_Jpan.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hun_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ell_Grek.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pap_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ary_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mya_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kaz_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nob_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mri_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kmr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/khm_Khmr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/dzo_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tsn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bjn_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ukr_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mal_Mlym.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fuv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/crh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tir_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/glg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/dyu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kas_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ace_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tam_Taml.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ben_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mlt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/azb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/rus_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/smo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/quy_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lit_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lua_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/als_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tzm_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mkd_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/knc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/san_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/heb_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pan_Guru.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tum_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kor_Hang.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tgk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/slv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/yue_Hant.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sat_Olck.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kan_Knda.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ltg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nya_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/yor_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/swh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tuk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ces_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ltz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/grn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bho_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/spa_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tel_Telu.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ars_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/vec_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ceb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/isl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sin_Sinh.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ban_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/pag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/dan_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nno_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kir_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ita_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/amh_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/acm_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lmo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sna_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/eng_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/scn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/aeb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bod_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/por_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/lus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bul_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/uig_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kmb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/awa_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/arz_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/dik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/urd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ydd_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/zho_Hant.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/min_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/mai_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/bel_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/slk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/xho_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hin_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/deu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/gaz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/fij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/kab_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/nld_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/ckb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hne_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/uzn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/khk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/jav_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/arb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/umb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/gle_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/hye_Armn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/tpi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/eus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/prs_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/srp_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloom-560M/sampling/sun_Latn.csv\n"
     ]
    }
   ],
   "source": [
    "## ZeroShot learning for SIB-200 dataset on Bloom-560M model with sampling\n",
    "\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomTokenizerFast\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "# Load ZeroShot learning model and tokenizer\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# List of labels to use for ZeroShot learning\n",
    "list_of_labels = [\"science/technology\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "\n",
    "# Function to predict category given text\n",
    "def predict_category(text):\n",
    "    prompt = f\"\\\"{text}\\\" What category does this sentence belong to? {', '.join(list_of_labels)}?? The correct answer is:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    result_length = len(tokens) + 10\n",
    "    generated_text = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                                                     max_length=result_length,\n",
    "                                                     do_sample=True,\n",
    "                                                     top_k=50,\n",
    "                                                     top_p=0.9\n",
    "                                                     )[0])\n",
    "\n",
    "    del inputs\n",
    "    \n",
    "    found_labels = 0\n",
    "    found_label = \"\"\n",
    "\n",
    "    for label in list_of_labels:\n",
    "        if label in generated_text[generated_text.find('??')+3:].lower():\n",
    "            found_labels += 1\n",
    "            found_label = label\n",
    "\n",
    "    if found_labels == 1:\n",
    "        return found_label, generated_text\n",
    "    else:\n",
    "        return \"N/A\", generated_text\n",
    "\n",
    "# Output directory for saving DataFrames\n",
    "output_directory = \"zero-shot/sib-200/Bloom-560M/sampling\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "for language in os.listdir(data_directory):\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category', 'generated_text'])\n",
    "    \n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"test.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Iterate through rows and compare predicted category with actual category\n",
    "            for index, row in df.iterrows():\n",
    "                text = row['text']\n",
    "                actual_category = row['category']\n",
    "\n",
    "                # Predict category using your ZeroShot learning model\n",
    "                predicted_category, generated_text = predict_category(text)\n",
    "\n",
    "                # Append the results to the DataFrame\n",
    "                results_df = results_df.append({'text': text,\n",
    "                                                'actual_category': actual_category,\n",
    "                                                'predicted_category': predicted_category,\n",
    "                                                'generated_text': generated_text}, ignore_index=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            # Save the results DataFrame to a CSV file in the output directory\n",
    "            results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            results_df.to_csv(results_file_path, index=False)\n",
    "            \n",
    "            print(f\"Results saved to {results_file_path}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "131b3ea4aee5e494",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bjn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/epo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kas_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mni_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/guj_Gujr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lvs_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kat_Geor.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/asm_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ibo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ewe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/acq_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/run_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/zul_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kea_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/zsm_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fao_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ace_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pbt_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bem_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/apc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/cym_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/vie_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/taq_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fra_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pes_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/zho_Hans.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/npi_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tha_Thai.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/som_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/est_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/min_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tgl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ast_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/gla_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mar_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/cat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/aka_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/knc_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/swe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ory_Orya.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/afr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/srd_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/szl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ssw_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ilo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mag_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ind_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kbp_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ayr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ajp_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/shn_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lao_Laoo.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/luo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lim_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/oci_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/twi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/plt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/arb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tat_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/war_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/snd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/taq_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ron_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hrv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bak_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kac_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/cjk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/azj_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hau_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/wol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sot_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/jpn_Jpan.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hun_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ell_Grek.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pap_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ary_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mya_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kaz_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nob_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mri_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kmr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/khm_Khmr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/dzo_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tsn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bjn_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ukr_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mal_Mlym.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fuv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/crh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tir_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/glg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/dyu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kas_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ace_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tam_Taml.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ben_Beng.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mlt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/azb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/rus_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/smo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/quy_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lit_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lua_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/als_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tzm_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mkd_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/knc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/san_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/heb_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pan_Guru.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tum_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kor_Hang.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tgk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/slv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/yue_Hant.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sat_Olck.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kan_Knda.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ltg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nya_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/yor_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/swh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tuk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ces_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ltz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/grn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bho_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/spa_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tel_Telu.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ars_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/vec_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ceb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/isl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sin_Sinh.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ban_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/pag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/dan_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nno_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kir_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ita_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/amh_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/acm_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lmo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sna_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/eng_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/scn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/aeb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bod_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/por_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/lus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bul_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/uig_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kmb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/awa_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/arz_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/dik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/urd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ydd_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/zho_Hant.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/min_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/mai_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/bel_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/slk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/xho_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hin_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/deu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/gaz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/fij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/kab_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/nld_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/ckb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hne_Deva.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/uzn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/khk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/jav_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/arb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/umb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/gle_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/hye_Armn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/tpi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/eus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/prs_Arab.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/srp_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/Bloomz-560M/beam-search/sun_Latn.csv\n"
     ]
    }
   ],
   "source": [
    "## ZeroShot learning for SIB-200 dataset on Bloom-560M model with beam search\n",
    "\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomTokenizerFast\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "# Load ZeroShot learning model and tokenizer\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# List of labels to use for ZeroShot learning\n",
    "list_of_labels = [\"science/technology\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "\n",
    "# Function to predict category given text\n",
    "def predict_category(text):\n",
    "    prompt = f\"\\\"{text}\\\" What category does this sentence belong to? {', '.join(list_of_labels)}?? The correct answer is:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    result_length = len(tokens) + 10\n",
    "    generated_text = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                                                     max_length=result_length,\n",
    "                                                     num_beams=4,\n",
    "                                                     no_repeat_ngram_size=2,\n",
    "                                                     early_stopping=True\n",
    "                                                     )[0])\n",
    "\n",
    "    del inputs\n",
    "\n",
    "    found_labels = 0\n",
    "    found_label = \"\"\n",
    "\n",
    "    for label in list_of_labels:\n",
    "        if label in generated_text[generated_text.find('??')+3:].lower():\n",
    "            found_labels += 1\n",
    "            found_label = label\n",
    "\n",
    "    if found_labels == 1:\n",
    "        return found_label, generated_text\n",
    "    else:\n",
    "        return \"N/A\", generated_text\n",
    "\n",
    "# Output directory for saving DataFrames\n",
    "output_directory = \"zero-shot/sib-200/Bloomz-560M/beam-search\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "for language in os.listdir(data_directory):\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category', 'generated_text'])\n",
    "\n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"test.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Iterate through rows and compare predicted category with actual category\n",
    "            for index, row in df.iterrows():\n",
    "                text = row['text']\n",
    "                actual_category = row['category']\n",
    "\n",
    "                # Predict category using your ZeroShot learning model\n",
    "                predicted_category, generated_text = predict_category(text)\n",
    "\n",
    "                # Append the results to the DataFrame\n",
    "                results_df = results_df.append({'text': text,\n",
    "                                                'actual_category': actual_category,\n",
    "                                                'predicted_category': predicted_category,\n",
    "                                                'generated_text': generated_text}, ignore_index=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            # Save the results DataFrame to a CSV file in the output directory\n",
    "            results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            results_df.to_csv(results_file_path, index=False)\n",
    "\n",
    "            print(f\"Results saved to {results_file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:41:21.676833642Z",
     "start_time": "2024-01-16T20:25:29.569144328Z"
    }
   },
   "id": "61ce972293181fe4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bjn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/epo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kas_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mni_Beng.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/guj_Gujr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lvs_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kat_Geor.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/asm_Beng.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ibo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ewe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/acq_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/run_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/zul_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kea_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/zsm_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fao_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ace_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pbt_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bem_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/apc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/cym_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/vie_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/taq_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fra_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pes_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/zho_Hans.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/npi_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tha_Thai.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/som_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/est_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/min_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tgl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ast_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/gla_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mar_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/cat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/aka_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/knc_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/swe_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ory_Orya.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/afr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/srd_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/szl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ssw_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ilo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mag_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ind_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kbp_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ayr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ajp_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/shn_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lao_Laoo.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/luo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lim_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/oci_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/twi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tur_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/plt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/arb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tat_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/war_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/snd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/taq_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ron_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hrv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bak_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kac_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/cjk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/azj_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hau_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/wol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sot_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/jpn_Jpan.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hun_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ell_Grek.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pap_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ary_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mya_Mymr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kaz_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nob_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mri_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kmr_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/khm_Khmr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/dzo_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tsn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bjn_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ukr_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mal_Mlym.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fuv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/crh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tir_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/glg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/dyu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kas_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pol_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ace_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tam_Taml.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ben_Beng.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mlt_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/azb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/rus_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/smo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/quy_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lit_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lua_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/als_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tzm_Tfng.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mos_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mkd_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/knc_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/san_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/heb_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fon_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pan_Guru.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hat_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tum_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kor_Hang.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tgk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/slv_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/yue_Hant.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sat_Olck.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kan_Knda.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ltg_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nya_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/yor_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/swh_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tuk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ces_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bug_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ltz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/grn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bho_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/spa_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tel_Telu.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ars_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/vec_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ceb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/isl_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sin_Sinh.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ban_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/pag_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/dan_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nno_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kir_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ita_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/amh_Ethi.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/acm_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lmo_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sna_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/eng_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/scn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/aeb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bod_Tibt.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/por_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/lus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bul_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/uig_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kmb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/awa_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/arz_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/dik_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nso_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/urd_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ydd_Hebr.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/zho_Hant.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kam_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/min_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/mai_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fin_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/bel_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/slk_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/xho_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hin_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/deu_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/gaz_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/fij_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/kab_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/nld_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/ckb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hne_Deva.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/uzn_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/khk_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/jav_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/arb_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/umb_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/gle_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/hye_Armn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/tpi_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/eus_Latn.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/prs_Arab.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/srp_Cyrl.csv\n",
      "Results saved to zero-shot/sib-200/PolyML-1b/sampling/sun_Latn.csv\n"
     ]
    }
   ],
   "source": [
    "## ZeroShot learning for SIB-200 dataset on PolyLM model with sampling\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "model_path = \"DAMO-NLP-MT/polylm-1.7b\"\n",
    "\n",
    "# Load ZeroShot learning model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, legacy=False, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# List of labels to use for ZeroShot learning\n",
    "list_of_labels = [\"science/technology\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "\n",
    "# Function to predict category given text\n",
    "def predict_category(text):\n",
    "    prompt = f\"\\\"{text}\\\" What category does this sentence belong to? {', '.join(list_of_labels)}?? The correct answer is:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    result_length = len(tokens) + 10\n",
    "    generated_text = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                                                     attention_mask=inputs.attention_mask,\n",
    "                                                     max_length=result_length,\n",
    "                                                     do_sample=True,\n",
    "                                                     top_k=50,\n",
    "                                                     top_p=0.9,\n",
    "                                                     pad_token_id=tokenizer.eos_token_id\n",
    "                                                     )[0])\n",
    "\n",
    "    del inputs\n",
    "    \n",
    "    found_labels = 0\n",
    "    found_label = \"\"\n",
    "\n",
    "    for label in list_of_labels:\n",
    "        if label in generated_text[generated_text.find('??')+3:].lower():\n",
    "            found_labels += 1\n",
    "            found_label = label\n",
    "\n",
    "    if found_labels == 1:\n",
    "        return found_label, generated_text\n",
    "    else:\n",
    "        return \"N/A\", generated_text\n",
    "\n",
    "# Output directory for saving DataFrames\n",
    "output_directory = \"zero-shot/sib-200/PolyLM-1.7b/sampling\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "for language in os.listdir(data_directory):\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category', 'generated_text'])\n",
    "\n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"test.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Iterate through rows and compare predicted category with actual category\n",
    "            for index, row in df.iterrows():\n",
    "                text = row['text']\n",
    "                actual_category = row['category']\n",
    "\n",
    "                # Predict category using your ZeroShot learning model\n",
    "                predicted_category, generated_text = predict_category(text)\n",
    "\n",
    "                # Append the results to the DataFrame\n",
    "                results_df = results_df.append({'text': text,\n",
    "                                                'actual_category': actual_category,\n",
    "                                                'predicted_category': predicted_category,\n",
    "                                                'generated_text': generated_text}, ignore_index=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            # Save the results DataFrame to a CSV file in the output directory\n",
    "            results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            results_df.to_csv(results_file_path, index=False)\n",
    "\n",
    "            print(f\"Results saved to {results_file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T00:48:52.331942517Z",
     "start_time": "2024-01-13T18:03:28.299922831Z"
    }
   },
   "id": "db72ba1a0fe6252c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to zero-shot/sib-200/PolyML-1b/beams-search/shn_Mymr.csv\n"
     ]
    }
   ],
   "source": [
    "## ZeroShot learning for SIB-200 dataset on PolyLM model with beam search\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "model_path = \"DAMO-NLP-MT/polylm-1.7b\"\n",
    "\n",
    "# Load ZeroShot learning model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, legacy=False, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# List of labels to use for ZeroShot learning\n",
    "list_of_labels = [\"science/technology\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "\n",
    "# Function to predict category given text\n",
    "def predict_category(text):\n",
    "    prompt = f\"\\\"{text}\\\" What category does this sentence belong to? {', '.join(list_of_labels)}?? The correct answer is:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    result_length = len(tokens) + 10\n",
    "    generated_text = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                                                     attention_mask=inputs.attention_mask,\n",
    "                                                     max_length=result_length,\n",
    "                                                     num_beams=4,\n",
    "                                                     no_repeat_ngram_size=2,\n",
    "                                                     early_stopping=True,\n",
    "                                                     pad_token_id=tokenizer.eos_token_id\n",
    "                                                     )[0])\n",
    "\n",
    "    del inputs\n",
    "\n",
    "    found_labels = 0\n",
    "    found_label = \"\"\n",
    "\n",
    "    for label in list_of_labels:\n",
    "        if label in generated_text[generated_text.find('??')+3:].lower():\n",
    "            found_labels += 1\n",
    "            found_label = label\n",
    "\n",
    "    if found_labels == 1:\n",
    "        return found_label, generated_text\n",
    "    else:\n",
    "        return \"N/A\", generated_text\n",
    "\n",
    "# Output directory for saving DataFrames\n",
    "output_directory = \"zero-shot/sib-200/PolyLM-1.7b/beam-search\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "for language in os.listdir(data_directory)[57:58]:\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category', 'generated_text'])\n",
    "\n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"test.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Iterate through rows and compare predicted category with actual category\n",
    "            for index, row in df.iterrows():\n",
    "                text = row['text']\n",
    "                actual_category = row['category']\n",
    "\n",
    "                # Predict category using your ZeroShot learning model\n",
    "                predicted_category, generated_text = predict_category(text)\n",
    "\n",
    "                # Append the results to the DataFrame\n",
    "                results_df = results_df.append({'text': text,\n",
    "                                                'actual_category': actual_category,\n",
    "                                                'predicted_category': predicted_category,\n",
    "                                                'generated_text': generated_text}, ignore_index=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            # Save the results DataFrame to a CSV file in the output directory\n",
    "            results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            results_df.to_csv(results_file_path, index=False)\n",
    "\n",
    "            print(f\"Results saved to {results_file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T17:53:29.444908092Z",
     "start_time": "2024-01-14T17:08:33.607887603Z"
    }
   },
   "id": "e3a081f3d2a79c69",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"SIB-200 languages - ACL.xlsx\")\n",
    "\n",
    "# Calculte F1 score for each language and add it to the DataFrame\n",
    "def calculate_f1(language, model, method):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    results_df = pd.read_csv(f\"zero-shot/sib-200/{model}/{method}/{language}.csv\")\n",
    "\n",
    "    # Replace NaN values with 'N/A'\n",
    "    results_df = results_df.fillna('N/A')\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1 = f1_score(results_df['actual_category'], results_df['predicted_category'], average='macro')\n",
    "\n",
    "    # Add the F1 score to the DataFrame\n",
    "    df.loc[df['Folder Name'] == language, f'F1 {model} {method}'] = f1\n",
    "\n",
    "# Iterate through languages and calculate F1 score for each language\n",
    "for language in df['Folder Name']:\n",
    "    # calculate_f1(language, \"Bloom-560M\", \"sampling\")\n",
    "    calculate_f1(language, \"Bloomz-560M\", \"beam-search\")\n",
    "    # calculate_f1(language, \"PolyLM-1.7b\", \"sampling\")\n",
    "    # calculate_f1(language, \"PolyLM-1.7b\", \"beam-search\")\n",
    "\n",
    "# Save the updated DataFrame to the Excel file\n",
    "df.to_excel(\"SIB-200 languages - ACL.xlsx\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T21:47:04.802224352Z",
     "start_time": "2024-01-16T21:47:03.238460266Z"
    }
   },
   "id": "7a2b195881c57d00",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53b9b7fd18554c20ae7bbccb624dfb9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/14.1G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "602d7547d8bd4d728fb58b6d07a287dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/223 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02877ac2df454fdf89aa437272723926"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de6635e235b44b3eb14c8156aba1a650"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5dc24eba14b49b7a9fe9be6eafb66e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "HIP out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 15.98 GiB of which 202.00 MiB is free. Of the allocated memory 15.58 GiB is allocated by PyTorch, and 752.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Move model to GPU if available\u001B[39;00m\n\u001B[1;32m     22\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 23\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# List of labels to use for ZeroShot learning\u001B[39;00m\n\u001B[1;32m     26\u001B[0m list_of_labels \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscience\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolitics\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msports\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhealth\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentertainment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeography\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/transformers/modeling_utils.py:1878\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1873\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1874\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1875\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1876\u001B[0m     )\n\u001B[1;32m   1877\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1878\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1156\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(convert)\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    829\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 833\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m fn(param)\n\u001B[1;32m    834\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/anaconda3/envs/sib200/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: HIP out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 15.98 GiB of which 202.00 MiB is free. Of the allocated memory 15.58 GiB is allocated by PyTorch, and 752.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#Ameeta\n",
    "## ZeroShot learning for SIB-200 dataset on Bloom-560M model with sampling\n",
    "\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomTokenizerFast\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Assuming data directory contains multiple subdirectories with test.tsv files\n",
    "data_directory = \"sib-200/data/annotated\"\n",
    "\n",
    "# Load ZeroShot learning model and tokenizer\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-7b1\")\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-7b1\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# List of labels to use for ZeroShot learning\n",
    "list_of_labels = [\"science\", \"travel\", \"politics\", \"sports\", \"health\", \"entertainment\", \"geography\"]\n",
    "\n",
    "# Function to predict category given text\n",
    "def predict_category(text):\n",
    "    prompt = f\"\\\"{text}\\\" What category does this sentence belong to? {', '.join(list_of_labels)}?? The correct answer is:\"\n",
    "    # prompt = f\"Classify each sentence into one of 7 classes: [{', '.join(list_of_labels)}] \\n Sentence: {text} \\n Class:\"\n",
    "    # prompt = f\"Here is a sentence: \\\"{text}\\\" This is list of categories: {', '.join(list_of_labels)}. \\n What category does this sentence belong to? Give me the correct category without extra text. \"\n",
    "    # prompt = f\"SENTENCE:\\n {text} \\n Is this SENTENCE science, travel, politics, sports, health, entertainment or geography? \\nOPTIONS:\\n-science \\n-travel \\n-politics \\n-sports \\n-health \\n-entertainment \\n-geography \\n-ANSWER:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "    result_length = len(tokens) + 10\n",
    "    generated_text = tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                                                     max_length=result_length,\n",
    "                                                     do_sample=True,\n",
    "                                                     top_k=50,\n",
    "                                                     top_p=0.9\n",
    "                                                     )[0])\n",
    "\n",
    "    del inputs\n",
    "\n",
    "    found_labels = 0\n",
    "    found_label = \"\"\n",
    "\n",
    "    for label in list_of_labels:\n",
    "        if label in generated_text[generated_text.find('??')+3:].lower():\n",
    "            found_labels += 1\n",
    "            found_label = label\n",
    "\n",
    "    if found_labels == 1:\n",
    "        return found_label, generated_text\n",
    "    else:\n",
    "        return \"N/A\", generated_text\n",
    "\n",
    "# Output directory for saving DataFrames\n",
    "output_directory = \"zero-shot/sib-200/Bloom-560M/sampling/Ameeta\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through subdirectories in the data directory\n",
    "# for language in os.listdir(data_directory):\n",
    "for language in ['eng_Latn']:\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['text', 'actual_category', 'predicted_category', 'generated_text'])\n",
    "\n",
    "    subdir = os.path.join(data_directory, language)\n",
    "    for file in os.listdir(subdir):\n",
    "        # Check if the file is a test.tsv file\n",
    "        if file.endswith(\"test.tsv\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            # Read the test.tsv file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "            # Iterate through rows and compare predicted category with actual category\n",
    "            for index, row in df.iterrows():\n",
    "                text = row['text']\n",
    "                actual_category = row['category']\n",
    "\n",
    "                # Predict category using your ZeroShot learning model\n",
    "                predicted_category, generated_text = predict_category(text)\n",
    "\n",
    "                # Append the results to the DataFrame\n",
    "                results_df = results_df.append({'text': text,\n",
    "                                                'actual_category': actual_category,\n",
    "                                                'predicted_category': predicted_category,\n",
    "                                                'generated_text': generated_text}, ignore_index=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            # Save the results DataFrame to a CSV file in the output directory\n",
    "            results_file_path = os.path.join(output_directory, f'{language}.csv')\n",
    "            results_df.to_csv(results_file_path, index=False)\n",
    "\n",
    "            print(f\"Results saved to {results_file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T01:38:23.111223228Z",
     "start_time": "2024-01-16T01:29:10.498995012Z"
    }
   },
   "id": "14607649042d5ebd",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "982bf05ee00a4cc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
